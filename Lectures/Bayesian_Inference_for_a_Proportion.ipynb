{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec6188b",
   "metadata": {},
   "source": [
    "## Bayesian Inference for a Proprtion\n",
    "\n",
    "\n",
    "* Example: Tokyo Express customers' dining preference  \n",
    "The owner wants to find out how popular is choice of Friday.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff850f85",
   "metadata": {},
   "source": [
    "### Step 0: Import necesasry packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, beta, betabinom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f2da6",
   "metadata": {},
   "source": [
    "### Step 1: Consider the percentage of customers' choice is Friday  \n",
    "Before giving out the survey, let's consider the possible values and corresponding probablities of $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_values = np.array([0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "prior_probs = np.array([0.125, 0.125, 0.250, 0.250, 0.125, 0.125])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359675d",
   "metadata": {},
   "source": [
    "Note that probabilities are reasonable due to **Axioms of Probability**  \n",
    "1. For any event $A$, $P(A) \\in [0, 1]$\n",
    "2. $P(U)=1$\n",
    "3. If $A_i$ and $A_j$ are disjoint, $P(A_i \\cup A_j)=P(A_i)+P(A_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.bar(prior_values, prior_probs, color='blue', width=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9839b31",
   "metadata": {},
   "source": [
    "### Step 2: Collect the data and Compute the likelihood of $p$  \n",
    "Out of the 20 responses, 12 say that their favorite day for eating out for dinner is Friday.  \n",
    "Quantitiy of interest: $p$, unknown, we're trying to make a inference about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24390fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "y = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac307b2",
   "metadata": {},
   "source": [
    "\n",
    "* **The Binomial Distribution**  \n",
    "1. One is repeating the same basic task $n$ times\n",
    "2. 2 outcomes - *success* or *failure*\n",
    "3. The probability of of *success* is always $p$\n",
    "4. The results of outcomes from different trials are independent\n",
    "\n",
    "\n",
    "Do you think that the survey is a Binomial Experiment?\n",
    "1. 20 people\n",
    "2. *success*: Choose Friday\n",
    "3. For simplicity, let's assume that people answered independently\n",
    "\n",
    "$$P(Y=k)={n \\choose k}p^k(1-p)^{n-k}, k=0,...,n$$\n",
    "* **Likelihood**  \n",
    "a function of unknown quantity of interest. After collecting data, in this case,\n",
    "$$L(p) = {20 \\choose 12}p^k(1-p)^{n-k}$$\n",
    "$Y:$ even though it is the random variable, but once we observed the data, it is now **fixed!**  \n",
    "\n",
    "In Bayesian Inference, we assume that data is fixed and parameter is unknown. We only need $n, k$ and possible values of $p$ when computing the likelihood function. Note that we don't need $\\pi_{\\text{owner}}(p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07edf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = binom.pmf(y, n, prior_values)\n",
    "\n",
    "result = np.transpose(np.array([prior_values, prior_probs, likelihoods]))\n",
    "df = pd.DataFrame(result, columns = ['p','prior','likelihood'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b6275",
   "metadata": {},
   "source": [
    "### Step 3: Compute posterior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5946ec3",
   "metadata": {},
   "source": [
    "$$\\pi(p_i|y)=\\frac{\\pi(p_i) \\times L(p)}{\\sum_{j}{\\pi(p_j) \\times L(p_j)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373707be",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = likelihoods * prior_probs\n",
    "sum_p = np.sum(products)\n",
    "posterior_probs = products / sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8566b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(prior_values, posterior_probs, color='blue', width=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f41c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = binom.pmf(y, n, prior_values)\n",
    "result = np.transpose(np.array([prior_values, prior_probs, likelihoods, products, posterior_probs]))\n",
    "df = pd.DataFrame(result, columns = ['p','prior','likelihood', 'product', 'posterior'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11b745",
   "metadata": {},
   "source": [
    "## Continuous prios - the Beta distribution\n",
    "\n",
    "\\* *From [wikipedia](https://en.wikipedia.org/wiki/Beta_distribution#Bayesian_inference)*  \n",
    "\n",
    "The Bayesian inference, the beta distribution is the **conjugate prior probability distribution** for the **Bernoulli**, **binomial**, **negative binomial** and **geometric distributions**. It is a suitable model for the random behavior of percentage and proportions.\n",
    "\n",
    "---\n",
    "The prior and posterior are called **conjugate distributions** if those are in the same distribution family, and such prior is called **conjugate prior**.\n",
    "\n",
    "* Advantages:\n",
    "1. Closed-form expression (algebraic expression). Without conjugate prior, numerical integral may be necessary\n",
    "2. Conjugate prior may give some intuition such as how likelihood funcion updates a prior distribution\n",
    "---\n",
    "\n",
    "For $0 \\leq x \\leq 1, \\alpha, \\beta > 0$\n",
    "\n",
    "$$f(x;\\alpha,\\beta)=\\frac{1}{B(\\alpha,\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1} $$\n",
    "\n",
    "### Properties\n",
    "1. **Mode**: The most likely value of the distribution  \n",
    "If $\\alpha, \\beta>1$, \n",
    "$$\\frac{\\alpha-1}{\\alpha+\\beta-2}$$  \n",
    "If not, it indicates **anti-mode**, the lowest point of the pdf  \n",
    "\n",
    "2. **Mean(Expectation)**:\n",
    "$$\\frac{\\alpha}{\\alpha+\\beta}$$\n",
    "3. **Variance**:\n",
    "$$\\text{var}(X)=\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$$\n",
    "\n",
    "### Bayesian Inference\n",
    "* $a, b$ represents how many **prior successes / failures** you think that there should be\n",
    "* $a+b$ shows how strong the prior assumption is.\n",
    "\n",
    "### Examples of Beta Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_beta(a, b):\n",
    "    x = np.linspace(beta.ppf(0.00001, a, b), beta.ppf(0.99999, a, b), 100)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "    plt.plot(x, beta.pdf(x, a, b), lw=3)\n",
    "    plt.title(f'Beta({a},{b})')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_params = np.array([[(0.5, 0.5), (0.5, 1), (0.5, 2)], \n",
    "                        [(1, 0.5), (1, 1), (1, 2)],\n",
    "                        [(4,0.5), (4,1), (4,2)]], \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64655079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta_params.shape)\n",
    "\n",
    "len_x, len_y, _ = beta_params.shape\n",
    "fig, axs = plt.subplots(len_x, len_y, sharex = True, figsize=(9,6))\n",
    "fig.add_subplot(111, frameon=False)\n",
    "for i, j in np.ndindex((len_x, len_y)):\n",
    "    a, b = beta_params[i, j]\n",
    "    # returns evenly spaced numbers over a specificed interval\n",
    "    x = np.linspace(beta.ppf(0.0001, a, b), beta.ppf(0.9999, a, b), 100)\n",
    "    axs[i, j].plot(x, beta.pdf(x, a, b), lw=3)\n",
    "    axs[i, j].set_title(f'Beta({a},{b})')\n",
    "    axs[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6ec3f",
   "metadata": {},
   "source": [
    "### How to choose a Beta curve to represent prior opinions?\n",
    "\n",
    "* Specify a Beta prior by specification of quantiles of the distribution  \n",
    "\n",
    "*quantile:* are about rank order of values. ex) middle quantile = medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882299eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_select(quantile1, quantile2):\n",
    "    def betaprior1(K, x, p):\n",
    "        def bisection_search(k, x, p):\n",
    "            EPS = 0.0001\n",
    "            lo = 0\n",
    "            hi = 1.0\n",
    "            flag = False\n",
    "            while (flag == False):\n",
    "                mid = (lo + hi) / 2.0\n",
    "                p0 = beta.cdf(x, k * mid, k * (1 - mid))\n",
    "                if (p0 < p):\n",
    "                    hi = mid\n",
    "                else:\n",
    "                    lo = mid\n",
    "                if abs(p0 - p) < EPS:\n",
    "                    flag = True\n",
    "            return mid\n",
    "        \n",
    "        return np.array([bisection_search(k, x, p) for k in K])\n",
    "    \n",
    "    p1 = quantile1['p']\n",
    "    x1 = quantile1['x']\n",
    "    p2 = quantile2['p']\n",
    "    x2 = quantile2['x']\n",
    "    \n",
    "    logK = np.linspace(-3, 8, num=100)\n",
    "    K = np.exp(logK) # sum of two shape parameters (sample size)\n",
    "    mids = betaprior1(K, x1, p1)\n",
    "    \n",
    "    prob2 = beta.cdf(x2, K * mids, K * (1 - mids))\n",
    "    cond = [(prob2 > 0) & (prob2 < 1)]\n",
    "    prob2 = np.extract(cond, prob2)\n",
    "    logK = np.extract(cond, logK)\n",
    "    K0 = np.exp(np.interp(p2, prob2, logK))\n",
    "    K0 = np.array(K0, ndmin=1)\n",
    "    m0 = betaprior1(K0, x1, p1)    \n",
    "    return np.round(K0 * m0, 2), np.round(K0 * (1 - m0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9673e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf(0 to 50th quantile) = 0.55\n",
    "a, b = beta_select({'p': 0.5, 'x': 0.55}, {'p': 0.9, 'x': 0.80})\n",
    "a, b = float(a), float(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0b99e",
   "metadata": {},
   "source": [
    "### Updating the beta prior\n",
    "\n",
    "* prior: beta\n",
    "$$p \\sim \\mathcal{B}(a,b)$$\n",
    "* likelihood: binomial, $n$ and $y$ are fixed after the observation\n",
    "$$Y \\sim B(n,p)$$\n",
    "* posterior: beta, it becomes the **moving average between sample mean and prior mean**\n",
    "$$p \\sim \\mathcal{B}(a+y,b+n-y)$$\n",
    "\n",
    "$$E(p|y)=\\frac{a+y}{a+b+n}=\\frac{a}{a+b}\\times\\frac{a+b}{a+b+n}+\\frac{y}{n}\\times\\frac{n}{a+b+n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, n = 8, 20\n",
    "\n",
    "x_axis = np.linspace(beta.ppf(0.00001, a, b), beta.ppf(0.99999, a, b), 100)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "plt.plot(x_axis, beta.pdf(x, a, b), lw=3, label=f'Beta({a:.2f}, {b:.2f})')\n",
    "plt.plot(x_axis, beta.pdf(x, a+y, b+n-y), lw=3, label=f'Beta({a+y:.2f},{b+n-y:.2f})')\n",
    "plt.legend()\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Density')\n",
    "plt.title('prior to posterior')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683fa64",
   "metadata": {},
   "source": [
    "## Bayesian inference with continuous priors\n",
    "### Bayesian hypothesis testing  \n",
    "Suppose one of the Toyko Express workers claims that at least 75% fo the customers prefer Friday. *Is this a reasonable claim?* From a Bayesian viewpoint,\n",
    "* Find the posterior probability that $p\\geq0.75$\n",
    "* Make a decision based on the value of the posterior probability:\n",
    "* If the probability is small, we can reject this claim\n",
    "\n",
    "If the posterior is known and well defined, calculate directly or use Monte-Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b421b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_area_cdf(lo, hi, a, b):\n",
    "    return beta.cdf(hi, a, b) - beta.cdf(lo, a, b)\n",
    "\n",
    "def beta_area_mcs(lo, hi, a, b):\n",
    "    sample_size = 50000\n",
    "    samples = np.random.random(sample_size)\n",
    "    beta_samples = beta.ppf(samples, a, b)\n",
    "    return sum(lo <= beta_samples) / sample_size\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 15.06\n",
    "b = 10.56\n",
    "print(f'cdf: {beta_area_cdf(0.75, 1.0, a, b):.4f}')\n",
    "print(f'mcs: {beta_area_mcs(0.75, 1.0, a, b):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97861345",
   "metadata": {},
   "source": [
    "### Bayesian credible intervals \n",
    "A 90% Bayesian credible interval is an interval contains 90% of the posterior probablity\n",
    "\n",
    "**Note - confident interval in frequentist:**  \n",
    "If we repeat this process large number of time, then 95% of the outcomes(confident intervals) will cover the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb29e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_interval_mid(p, a, b):\n",
    "    assert 0 <= p and p <= 1\n",
    "    t = (1 - p) / 2\n",
    "    s = beta.ppf(t, a, b)\n",
    "    e = beta.ppf(1 - t, a, b)\n",
    "    x_axis = np.linspace(beta.ppf(1e-9, a, b), beta.ppf(1 - 1e-9, a, b))\n",
    "    plt.plot(x_axis, beta.pdf(x_axis, a, b), lw=3)\n",
    "    plt.axvspan(s, e, color='red')\n",
    "    plt.xlabel('p')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'{int(p*100)}% credible interval of Beta({a:.2f}, {b:.2f})')\n",
    "    plt.show()\n",
    "    print(f'{s:.3f} <= p <= {e:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_interval_mid(0.9, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25c2c7",
   "metadata": {},
   "source": [
    "### Bayesian prediction  \n",
    "Outcome values simulated from the posterior predictive distribution, which is the distribution of the unobserved (future) data given the observed data. They can be used as optimal predictors in forecasting, inputations for missing data, and more. They are also important for checking *model goodness of fit*.\n",
    "\n",
    "---\n",
    "\n",
    "Suppose the Toyko Express owner gives out another survey to $m$ customers, how many would prefer Friday?  \n",
    "Let $Y$ be a random variable representing (maybe future) data. We have a parameteric model for $Y$ with $Y \\sim f(y|\\theta), \\theta \\in \\Theta$, where $\\Theta$ is the parameter space and prior distribution as $\\pi(\\theta)$.\n",
    "* The *prior predictive distribution* of $Y$: $$f(y)=\\int_{\\Theta}{f(y|\\theta)\\pi(\\theta)d\\theta}$$  \n",
    "It is a collection of data sets generated from the model(the likelihood and parameters). This tells you what data$(Y)$ you expect to see before learning more about $\\theta$.\n",
    "* The posterior-predictive distribution: $$p(\\tilde{y}|y)=\\int{p(\\tilde{y},\\theta|y)d\\theta}=\\int{p(\\tilde{y}|\\theta)p(\\theta|y)d\\theta}$$  \n",
    "After we have seen the data and obtained the posterior distributions of the parameters, we can now *use* the posterior distributions to generate futrue data from the model. In other words, it gives us some indication of what future data might look like. We get some approximation by simulation. In this example,  \n",
    "$$\\text{sample }p \\sim \\mathcal{B}(a+y,b+n-y) \\rightarrow \\text{sample } \\tilde{y} \\sim B(m,p)$$\n",
    "\n",
    "reference:  \n",
    "https://stats.stackexchange.com/questions/394648/differences-between-prior-distribution-and-prior-predictive-distribution  \n",
    "https://vasishth.github.io/bayescogsci/book/sec-ppd.html  \n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Beta-binomial_distribution),  \n",
    "* (The exact prediction): Beta-binomial distribution $f(k|n,\\alpha,\\beta)$,  \n",
    "the binomial distribution in which the probability of success at each of $n$ trials is not fixed but randomly drawn from a beta distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1234)\n",
    "\n",
    "sample_size = 1000\n",
    "\n",
    "a = 3.06\n",
    "b = 2.56\n",
    "\n",
    "n = 20\n",
    "y = 12\n",
    "\n",
    "m = 20\n",
    "pred_p_sim = beta.rvs(a + y, b + n - y, size=sample_size)\n",
    "pred_y_sim = []\n",
    "for p in pred_p_sim:\n",
    "    pred_y_sim.append(binom.rvs(m, p))\n",
    "pred_y_sim = np.array(pred_y_sim)\n",
    "sim = pred_y_sim\n",
    "# what is the probability that predictive number of successes lies on betwwen 5 and 15?\n",
    "sim_result = (pred_y_sim >= 5) & (pred_y_sim <= 15)\n",
    "print(f'result by simulation: {sum(sim_result) / sample_size:.4f}')\n",
    "\n",
    "# exact solution by beta-binomal distribution!\n",
    "ext = betabinom.rvs(m, a + y, b + n - y, size=sample_size)\n",
    "ext_result = (ext >= 5) & (ext <= 15)\n",
    "print(f'result by simulation: {sum(ext_result) / sample_size:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e5bf1",
   "metadata": {},
   "source": [
    "**Compare results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd09137",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex = True, sharey=True, figsize=(10, 5))\n",
    "x_axis = np.linspace(0, 20, 21)\n",
    "ax[0].hist(ext, bins=x_axis, rwidth=0.7)\n",
    "ax[0].set_title('Simulation')\n",
    "ax[1].hist(sim, bins=x_axis, rwidth=0.7)\n",
    "ax[1].set_title('Exact')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6da5ea",
   "metadata": {},
   "source": [
    "### Posterior predictive checking  \n",
    "\n",
    "*Sometimes, we make new prediction and then check our **original observation** against the prediction to see how well our model is doing.*  \n",
    "\n",
    "$$\\text{sample }p \\sim \\mathcal{B}(a+y,b+n-y) \\rightarrow \\text{sample } \\tilde{y} \\sim B(n,p)$$  \n",
    "\n",
    "The sample $\\{\\tilde{y}^{(1)}, \\tilde{y}^{(2)}, ..., \\tilde{y}^{(S)}\\}$ is an approximation to the posterior predictive distribution that can be used for model checking. Frequent observations of extreme values from the simulation indicate that the model is not good (or stable)  \n",
    "\n",
    "The observed value of $y$ is consistent with simulations of replicated data from this predictive distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p_sim = beta.rvs(a + y, b + n - y, size=sample_size)\n",
    "pred_y_sim = []\n",
    "for p in pred_p_sim:\n",
    "    pred_y_sim.append(binom.rvs(n, p))\n",
    "pred_y_sim = np.array(pred_y_sim)\n",
    "sim = pred_y_sim\n",
    "\n",
    "plt.figure(1, figsize=(9, 6))\n",
    "# on y=12\n",
    "plt.axvspan(12, 13, color='red')\n",
    "plt.hist(sim, bins=x_axis, rwidth=0.7)\n",
    "plt.title('posterior predictive distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940b9b5",
   "metadata": {},
   "source": [
    "If either $p(y>\\tilde{y}|y)$ or $p(y<\\tilde{y}|y))$ is small, it suggest that the model does not describe $y$ very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b13279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(sim > y) / sample_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
